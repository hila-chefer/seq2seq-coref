Namespace(adam_beta1=0.9, adam_beta2=0.98, adam_epsilon=1e-06, amp=True, batch_size_1=False, cache_dir='/media/data2/hila_chefer/seq2seq-coref/cache', config_name='allenai/longformer-large-4096', conll_path_for_eval='/media/data2/hila_chefer/seq2seq-coref/data/test', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, dropout_prob=0.3, eval_steps=1000, experiment_name='eval_model', ffnn_size=3072, fp16_opt_level='O1', gradient_accumulation_steps=1, head_learning_rate=0.0003, learning_rate=1e-05, local_rank=-1, logging_steps=500, max_seq_length=4096, max_span_length=30, max_total_seq_len=5000, model_name_or_path='/media/data2/hila_chefer/seq2seq-coref/model', model_type='longformer', n_gpu=8, no_cuda=False, nonfreeze_params=None, normalise_loss=True, num_train_epochs=129.0, output_dir='/media/data2/hila_chefer/seq2seq-coref/output', overwrite_output_dir=False, predict_file='/media/data2/hila_chefer/seq2seq-coref/data/test.english.jsonlines', predict_file_cache='/media/data2/hila_chefer/seq2seq-coref/data/test.english.4096.pkl', save_if_best=True, save_steps=3000, seed=42, tensorboard_dir='/media/data2/hila_chefer/seq2seq-coref/output/tb', tokenizer_name='allenai/longformer-large-4096', top_lambda=0.4, train_file='/media/data2/hila_chefer/seq2seq-coref/data/train.english.jsonlines', train_file_cache='/media/data2/hila_chefer/seq2seq-coref/data/train.english.4096.pkl', warmup_steps=5600, weight_decay=0.01)